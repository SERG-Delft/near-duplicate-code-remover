# Near-Duplicate Code Detector

This cross-platform sample tool detects exact and near duplicates of code maintained by the [Deep Program Understanding](https://www.microsoft.com/en-us/research/project/program/) group in Microsoft Research, Cambridge, UK. It has been created for the purpose of deduplicating code corpora for research purposes.

*Requirements*: 
* .NET Core 2.1 for parsing code, an appropriate runtime for each of the languages that needs to be tokenized is also required.
* Java 1.8 for tokenizing Java code
* Python for removing found duplicates from code. 

### Duplicate Detection and Removal
Duplicate removal consists of tokenizing the code, detecting duplicates, copying the dataset and then 
removing the duplicates from copy. This results with a deduplicated copy and untouched original dataset. 
A convenient shell script is provided for this, just run:  
NOTE: Works only for JAVA
```
sh deduplicate.sh target/project/path output/path/
```
* After script finishes, you can find deduplicated dataset under `output/path/`
You can optionally skip the argument and specify the path in the shell script by changing 
`DEFAULT_TARGET_PROJECT_PATH` value. Same goes for output path.

### Running Tokenizer  
For java, run:
`java -jar tokenizers/java/target/javatokenizer-1.0-SNAPSHOT.jar /path/to/target/project/ ./output true`  
The last boolean is for granularity:  
* true - look only at identifier tokens
* false - look at identifier names + all tokens, including things like ";" and operators like "<", "||", etc.

### Duplicate Detection
To run the near-duplicate detection run:
```
$ dotnet run /path/to/DuplicateCodeDetector.csproj --project /path/to/DuplicateCodeDetector/ --dir=<folder>
```
This will use all the `.gz` files in the `<folder>` generated by tokenizer and output 
`DuplicateCodeDetector/CloneDetectorCli.json` file with the groups of detected duplicates. 
Invoke `--help` for more options.

### Input Data

The input data should be one or more `.jsonl.gz` files. These are compressed [JSONL](http://jsonlines.org/) files where each line has a single JSON entry of the form
```
{
    "filename": "unique identifier of file, such as a path or a unique id",
    "tokens" : ["list", "of", "tokens", "in", "file"]
}
```
Alternative formats can be accepted by providing the `--tokens-field` and `--id-fields` options.

The `tokenizers` folder in this repository contains tokenizers for 
C\#, Java, JavaScript and Python. Please, feel free to contribute tokenizers for other languages too.

### Duplicate Removal
Once code is tokenized and clones are detected, a removal script can be run.
`python deduplicate.py --project project/to/deduplicate --duplicates_data data/generated/by/duplicate/detection`

# Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
